---
title: "Thesis_MLR"
author: "Darian Ng"
date: "04/06/2023"
output: html_document
---

```{r setup, include=FALSE}
library(reticulate)
use_python("/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9")
library(nlme)
library(MASS)
library(car)


## Including Plots


site_name = 'Young'
dataPath = '/Users/darianng/Documents/MSc_Geography/MSc Thesis/Data/Compilation/'
ex_dates = c('20210909','20220818')
# Training data
data <- pd$read_pickle(paste(dataPath,site_name,"_Annual/21to23_growing_season_ex_",
                             ex_dates[1],"_",ex_dates[2],"/compiled_data.p",sep=""))
# Validation data
obs_data <- pd$read_pickle(paste(dataPath,site_name,"_Annual/21to23_growing_season_",
                                 ex_dates[1],"_",ex_dates[2],"/compiled_data.p",sep=""))

full_data <- pd$read_pickle(paste(dataPath,site_name,"_Annual/21to23_growing_season/compiled_data.p",sep=""))

# Training model on all data - 2021-07-14 (or 2022-08-18, or 2021-08-31) & 2021-09-25 (or 2021-09-09)
# Skipping: 2021-09-09, 2022-08-18
NDVI <- unlist(data$collapsed_landsat$NDVI)
NDWI <- unlist(data$collapsed_landsat$NDWI)
NDMI <- unlist(data$collapsed_landsat$NDMI)
temp <- unlist(data$collapsed_landsat$temp)
month.f <- as.factor(data$collapsed_landsat$month)
year.f <- as.factor(data$collapsed_landsat$year)
CH4 <- unlist(data$collapsed_ffp)

df<-data.frame(NDVI,NDWI,NDMI,temp,month.f,year.f,CH4)

# NDVI_obs <- unlist(footprint_data$landsat$NDVI) # Cluster example
# month.f <- as.factor(rep(as.numeric(substr(test_date,5,6)),length(NDVI_obs))) # Cluster example
NDVI_obs <- unlist(obs_data$collapsed_landsat$NDVI)
NDWI_obs <- unlist(obs_data$collapsed_landsat$NDWI)
NDMI_obs <- unlist(obs_data$collapsed_landsat$NDMI)
temp_obs <- unlist(obs_data$collapsed_landsat$temp)
month.f <- as.factor(obs_data$collapsed_landsat$month)
year.f <- as.factor(obs_data$collapsed_landsat$year)
period_obs <- unlist(obs_data$collapsed_landsat$period)
CH4_obs <- unlist(obs_data$collapsed_ffp)
df_obs <- data.frame(NDVI_obs,NDWI_obs,NDMI_obs,temp_obs,month.f,year.f,period_obs,CH4_obs)
colnames(df_obs) <- c('NDVI','NDWI','NDMI','temp','month.f','year.f','period','CH4')

# NDVI_clustered load
L8_clus <- pd$read_pickle(paste(dataPath,site_name,"_Annual/2021_growing_season/NDVI_clustered_20210909.p",sep=""))
month <- as.factor(rep(9,length(L8_clus$NDVI)))
L8_clus_20210909 = data.frame(L8_clus$NDVI,L8_clus$NDWI,L8_clus$NDMI,L8_clus$temp,month,L8_clus$CH4)
colnames(L8_clus_20210909) <- c('NDVI','NDWI','NDMI','temp','month.f','CH4')

L8_clus <- pd$read_pickle(paste(dataPath,site_name,"_Annual/2022_growing_season/NDVI_clustered_20220818.p",sep=""))
month <- as.factor(rep(8,length(L8_clus$NDVI)))
L8_clus_20220818 = data.frame(L8_clus$NDVI,L8_clus$NDWI,L8_clus$NDMI,L8_clus$temp,month,L8_clus$CH4)
colnames(L8_clus_20220818) <- c('NDVI','NDWI','NDMI','temp','month.f','CH4')


weights = varPower(form=~yhat.LME01)
model0 <- gls(CH4 ~ month.f + NDVI + NDWI+ NDMI+ temp
              ,data=df,method="ML")
model1 <- gls(CH4 ~ month.f + NDVI + NDWI+ NDMI+ temp
              + month.f*NDVI+ month.f*NDWI+month.f*NDMI+month.f*temp,data=df,method="ML"
              , correlation = corCAR1(form = ~1|month.f))

model2 <- gls(CH4 ~ month.f + NDVI + NDWI+ NDMI
              + month.f*NDVI+ month.f*NDWI,data=df,method="ML",
              correlation = corCAR1(form = ~1|month.f))

model2test <- gls(CH4 ~ month.f + NDVI + NDWI+ NDMI
              + month.f*NDVI+ month.f*NDWI,varPower(form=~CH4),data=df,
              method="ML",correlation = corCAR1(form = ~1|month.f))

library(lme4)
# Proper mixed effect full
model3 <- lmer(CH4 ~ NDVI+ NDWI+ NDMI+temp + (1|month.f)
               +(1+NDVI|month.f)+(1+NDWI|month.f)+(1+NDMI|month.f)+(1+temp|month.f)
               ,data=df,REML=F)
model3 <- update(model3, correlation = corAR1())

# Proper mixed effect Reduced, no autocorr
model4_nocorr <- lmer(CH4 ~ NDVI+ NDWI+ NDMI+temp + (1|month.f)
               +(1+NDVI|month.f)+(1+NDWI|month.f),data=df,REML=F)

null_model <- lm(CH4 ~ month.f+NDVI+ NDWI+ NDMI + temp,data=df)

# model3_fixed <- lm(CH4 ~ month.f+NDVI+ NDWI+ NDMI + temp 
#                    +NDVI*month.f+NDWI*month.f+NDMI*month.f+temp*month.f
#                    ,data=df)
model3_fixed <- lm(CH4 ~ month.f+NDVI+ NDWI+ NDMI + temp,data=df)
model4_fixed <- lm(CH4 ~ month.f+ NDWI+ NDMI +temp+ temp*month.f,data=df)
# model4_fixed <- lm(CH4 ~ month.f+ NDVI+NDWI+ NDMI+ NDVI*month.f+NDWI*month.f,data=df)


model5 <-lm(CH4 ~ month.f +NDVI+ NDWI +NDMI + temp+ month.f*NDVI+month.f*NDWI,data=df)

dwtest(model5)
```

```{r}
model.step <- stepAIC(model3_fixed,
                scope = list(upper = ~month.f+NDVI+NDWI+NDMI+temp
                             +month.f*NDVI+ month.f*NDWI+ month.f*NDMI+ month.f*temp
                             ,lower = ~1)
                ,direction='both',trace = 1)
```
```{r}
shapiro.test(resid(model1))
shapiro.test(resid(model2))
resid_plot2(model1,df,"Full Model")
resid_plot2(model2,df,"Reduced Model")
# interaction.plot(df$NDWI,df$month.f,df$CH4,type = "l",ylab='CH4',xlab='NDVI')
pairs(~ CH4+NDVI + NDWI + NDMI + temp + month.f, data=df, main="Scatterplot Matrix for CH4 data",pch = 20)
```

```{r}
# Plot Prediction!
num_obs = length(unique(df_obs$period))
par(mfrow=c(1,2), cex=1.0, mai=c(1.3,1,1.3,0.3)) # Bottom,left,top,right
corr1_r <- c(); corr1_p <- c(); fit1 <- c()
corr2_r <- c(); corr2_p <- c(); fit2 <- c()
plot_model1 <- null_model
plot_model2 <- model4_fixed
model1_name <- 'Main Effects Model'
model2_name <- 'Reduced Model'
count <- 1
for (ob in unique(df_obs$period)){
  
  subset_df <- subset(df_obs, period == ob)
  yhat1 <- predict(plot_model1,newdata=subset_df)
  yhat2 <- predict(plot_model2,newdata=subset_df)
  x <- subset_df$CH4
  plot_min <- min(c(min(x),min(yhat1),min(yhat2)))
  plot_max <- max(c(max(x),max(yhat1),max(yhat2)))
  plot(x,yhat1,pch=4,col='black',main = ob,xlim = c(plot_min-5, plot_max+5), ylim = c(plot_min-20, plot_max+20),xlab = 'Observed FCH4', ylab = 'Predicted FCH4',cex = 1)
  points(x,yhat2,pch=1,col='blue',cex = 1)
  mtext(paste(LETTERS[count],')'), adj=0, line=1)

  abline(a=0,b=1,col="red") 
  
  linear1 <- lm(yhat1 ~ x)
  linear2 <- lm(yhat2 ~ x)
  linear_fit <- linear1$coefficients[1] + linear1$coefficients[2] * x
  linear_fit2 <- linear2$coefficients[1] + linear2$coefficients[2] * x
  lines(x,linear_fit,col='black')
  lines(x,linear_fit2,col='blue')
  
  legend("topright", legend = c(model1_name,model2_name), col = c( "black","blue"), lwd = 1,xpd = TRUE,bty='n',inset=c(0, -.28),xjust=1)
  
  r1 <- cor.test(x, yhat1)$estimate
  r2 <- cor.test(x, yhat2)$estimate
  p1 <- cor.test(x, yhat1)$p.value
  p2 <- cor.test(x, yhat2)$p.value
  corr1_r <- c(corr1_r,r1); corr1_p <- c(corr1_p,p1)
  corr2_r <- c(corr2_r,r2); corr2_p <- c(corr2_p,p2)
  fit1 <- c(fit1, linear1$coefficients)
  fit2 <- c(fit2, linear2$coefficients)
  count <- count + 1
}
corr = data.frame(corr1_r,corr1_p,corr2_r,corr2_p,unique(df_obs$period))
colnames(corr) <- c('model1_r','model1_p','model2_r','model2_p','period')
# fit1; fit2

par(mfrow=c(1,1), cex=1.0, mai=c(1.0,1.0,1.0,1.0) ) 
```
```{r}
# SAVE
save_model <- model2
save_df <- df
df_coeff <- coefficients(save_model)
save_df$fitted <- fitted(save_model,level=0)

savedir = "/Users/darianng/Documents/MSc_Geography/MSc Thesis/Data/Model/"
setwd(savedir)
write.csv(save_df, file = "model2_Reduced_model.csv", row.names = TRUE)
write.csv(df_coeff, file = "model2_Reduced_model_coeff.csv", row.names = TRUE)
print('Saved')
```


```{r}
# par(mfrow=c(1,2), cex=1.0, mai=c(1.3,1,1.3,0.3)) #(1,2) plots
resid_plot2 <- function (model_1,model_2,df){
  par(mfrow=c(2,2), cex=1.0, mai=c(1.0,1.2,0.6,0.6))# Bottom,left,top,right
  # Fitted line plot. Predicted y versus observed y.
  plot(df$CH4, fitted(model_1), xlab=expression(Predicted~FCH[4]~(nmol/m^2/s)), 
       ylab=expression(atop(Predicted~FCH[4],(nmol/m^2/s))), main="Main Effects Model\nPredicted y Plot",
       pch=19,cex.main=1)
  abline(a=0,b=1,col="red") 
  mtext(paste(LETTERS[1],')'), adj=-0.2, line=1)
  plot(fitted(model_1),resid(model_1), main="Main Effects Model\nResidual Plot"
       ,ylab = "Residuals", xlab=expression(Predicted~FCH[4]~(nmol/m^2/s)),cex.main=1)
  abline(a=0,b=0, col="red")  # residual plot
  mtext(paste(LETTERS[2],')'), adj=-0.2, line=1)
  plot(df$CH4, fitted(model_2), xlab=expression(Predicted~FCH[4]~(nmol/m^2/s)), 
       ylab=expression(atop(Predicted~FCH[4],(nmol/m^2/s))), main=paste("Reduced Model\nPredicted y Plot"),
       pch=19,cex.main=1)
  abline(a=0,b=1,col="red") 
  mtext(paste(LETTERS[3],')'), adj=-0.2, line=1)
  plot(fitted(model_2),resid(model_2), main="Reduced Model\nResidual Plot"
       ,ylab = "Residuals", xlab=expression(Predicted~FCH[4]~(nmol/m^2/s)),cex.main=1)  
  abline(a=0,b=0, col="red")  # residual plot
  mtext(paste(LETTERS[4],')'), adj=-0.2, line=1)
  par(mfrow=c(1,1), cex=1.0, mai=c(1.0,1.0,1.0,1.0) ) 
  # mtext(deparse(model$call[2]),side = 3,line = 4,outer = FALSE)
}
resid_plot2(null_model,model4_fixed,df)
```

```{r}
# PREDICT ON NDVI_CLUSTERED
test_data <- list(L8_clus_20210909,L8_clus_20220818)
test_dates <- c('20210909','20220818')
num_obs <- length(test_data)
par(mfrow=c(1,2), cex=1.0, mai=c(1.3,1,1.3,0.3)) # Bottom,left,top,right
corr1_r <- c(); corr1_p <- c(); fit1 <- c()
corr2_r <- c(); corr2_p <- c(); fit2 <- c()
count = 1
for (ob in test_data){
  
  yhat1 <- predict(model1,newdata=ob)
  yhat2 <- predict(model2,newdata=ob)
  x <- ob$CH4
  plot_min <- min(c(min(x),min(yhat1),min(yhat2)))
  plot_max <- max(c(min(x),max(yhat1),max(yhat2)))
  plot(x,yhat2,pch=19,col='blue',main = test_dates[count],xlim = c(plot_min-5, plot_max-40), ylim = c(plot_min-20, plot_max+20),xlab = 'Observed FCH4', ylab = 'Predicted FCH4')
  points(x,yhat1,pch=19,col='black')

  abline(a=0,b=1,col="red") 
  
  linear1 <- lm(yhat1 ~ x)
  linear2 <- lm(yhat2 ~ x)
  linear_fit <- linear1$coefficients[1] + linear1$coefficients[2] * x
  linear_fit2 <- linear2$coefficients[1] + linear2$coefficients[2] * x
  lines(x,linear_fit,col='black')
  lines(x,linear_fit2,col='blue')
  
  legend("topright", legend = c("Residual Model","Full Model"), col = c( "blue","black"), lwd = 1,xpd = TRUE,bty='n',inset=c(0, -.28),xjust=1)
  
  r1 <- cor.test(x, yhat1)$estimate
  r2 <- cor.test(x, yhat2)$estimate
  p1 <- cor.test(x, yhat1)$p.value
  p2 <- cor.test(x, yhat2)$p.value
  corr1_r <- c(corr1_r,r1); corr1_p <- c(corr1_p,p1)
  corr2_r <- c(corr2_r,r2); corr2_p <- c(corr2_p,p2)
  fit1 <- c(fit1, linear1$coefficients)
  fit2 <- c(fit2, linear2$coefficients)
  count = count + 1
}
corr = data.frame(corr1_r,corr1_p,corr2_r,corr2_p,unique(df_obs$period))
colnames(corr) <- c('Full_r','Full_p','Reduced_r','Reduced_p','period')
fit1; fit2

par(mfrow=c(1,1), cex=1.0, mai=c(1.0,1.0,1.0,1.0) ) 
```
```{r}
# Random forest?
library(lubridate) # work with dates
library(dplyr)     # data manipulation (filter, summarize, mutate)
library(ggplot2)   # graphics
library(here)
library(plotly)
library(Metrics)
library(pdp)
library(vip)
library(ranger)
library(caret)
library(corrr)
```


```{r}
# Random forest?

## Create tune-grid (all combinations of hyper-parameters)
tgrid <- expand.grid(
  mtry = c(2, 3, 4, 5, 6),
  splitrule = "variance",
  min.node.size = c(5, 50, 100)
)
## Create trainControl object (other )
myControl <- trainControl(
  method = "cv",
  allowParallel = TRUE,
  verboseIter = TRUE,  ## I think this is required for varimp analyses
  returnData = FALSE,
)
## train rf
set.seed(500)
rf_model <- train(
  CH4 ~ .,
  data = df,
  num.trees = 500, # start at 10xn_feat, maintain at 100 below 10 feat
  method = 'ranger',
  trControl = myControl,
  tuneGrid = tgrid,
  importance = 'permutation',  ## or 'impurity'
  metric = "MAE" ## or 'rmse'
)
rf_model$bestTune
rf_model$finalModel


#generate FCH4_rf predictions for test set

ob = unique(df_obs$period)[1]
subset_df_obs <- subset(df_obs, period == ob)
  
subset_df_obs$CH4_rf <- predict(rf_model, subset_df_obs, na.action = na.pass)
regrRF <- lm(subset_df_obs$CH4_rf ~ subset_df_obs$CH4);
regrRF
ggplot(subset_df_obs, aes(x=CH4, y=CH4_rf)) + geom_abline(slope = 1, intercept = 0)+
  geom_point() + geom_smooth(method = "lm") + ggtitle(as.character(ob))

r = cor.test(subset_df_obs$CH4,subset_df_obs$CH4_rf)

```

